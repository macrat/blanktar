zfsの重複排除で未来を感じてみる
2013-07-09 02:15
keywords: ファイルシステム zfs 重複排除

<b>追記:</b> 日付がおかしくなってた問題を修正。ごめんなさい。
あと、zfsのデータ圧縮も試してみました。 [ついでにzfsのデータ圧縮も試してみる](/blog/2013/07/zfs-data-compress.html)

重複排除を試してみたい。というか、試してみました。ので、メモ。
いやー、これはいい。安定性がどうなのかってところはあるけれどね。

-- インストールと設定
    今回はubuntuで試したので、インストールはこんな感じ。
        # apt-get install zfs-fuse

    無事インストールできたら、HDD代わりにファイルを作成します。
    なにゆえファイルなのかというと、HDDが余ってないから。
    余ってる方はそれで問題ないので、この手順はスキップしてください。
        $ head -c 100M /dev/zero > /tmp/testfile
    こんな感じね。

    さて、いよいよ本命、ストレージプールを作成。
        # zpool create testpool /tmp/testfile
    これだけ。
    作成と同時に/testpoolにマウントされます。

    マウントポイントを移動するときは
        # zfs set mountpoint=/tmp/test testpool
    こんな感じで。
    ちなみに、マウント先のディレクトリは存在しなくてもおっけーです。

    で、重複排除を有効にします。
        # zfs set dedup=on testpool
    こんな感じ。再起動とか再マウントとかの必要はなし。あら素敵。

-- 試してみる
    さあいよいよ実験だ。
    ファイルを100MBで作成したので、このHDDモドキの容量は100MBです。
    という訳で、その限界を突破してみましょう。

        # head -c 1G /dev/zero > /testpool
    100Mのディスクに1Gのファイルを詰め込む！　おお、なんてキモチワルイ。
    キモチワルイですが、難なく成功するはずです。

    ちなみに、dfコマンド使えば現在の使用量を見る事が出来ます。
    見る事ができるのだけれど、重複してるファイルを追加すると最大容量も増えてくのね。
    いやー、キモチワルイ。

    まあ、実際は0x00だけのファイルなんて理想的なものがあるはず無いので、現実的な実験じゃないけれど。
    当然、/dev/zeroの代わりに/dev/urandomあたりから書き込むと一瞬で使い切ります。
    いやー、面白い。

-- 後片付け
    そんな感じで遊び終わったら、後片付け。

        # zpool destroy testpool
    これでアンマウント出来ます。
    多分これでおっけー。多分。
