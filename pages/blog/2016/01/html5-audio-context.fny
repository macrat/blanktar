title: HTML5でマイクで拾った音を色々して何か作った。
date: 2016-01-10 22:13
keywords: HTML5 javascript 音 波形 フーリエ変換 canvas

なんか面白いものを作ろうかと思って、HTML5の[AnalyzerNode](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode)とやらを使ってみました。
細かいことはともかくとして、大雑把に使い方を。

なんかこんな感じのやつが出来る。マイクの付いた新しめのブラウザでご覧下さい。
<canvas style="border: 1px solid black; background-color: white;" width=640 height=480 id=mic_frequency_one></canvas>

ソースコードはこんな感じです。
``` html
	<audio muted></audio>
	<canvas width=640 height=480></canvas>
	<script>
	navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;

	var canvas = document.querySelector('canvas');
	var context = canvas.getContext('2d');

	canvas.width = canvas.offsetWidth;
	canvas.height = canvas.offsetHeight;

	navigator.getUserMedia(
		{audio : true},
		function(stream){
			document.querySelector('audio').src = URL.createObjectURL(stream);
			var audioContext = new AudioContext();
			var analyser = audioContext.createAnalyser();
			var timeDomain = new Float32Array(analyser.frequencyBinCount);
			var frequency = new Uint8Array(analyser.frequencyBinCount);
			audioContext.createMediaStreamSource(stream).connect(analyser);

			(function animation(){
				analyser.getFloatTimeDomainData(timeDomain);
				analyser.getByteFrequencyData(frequency);

				context.clearRect(0, 0, canvas.width, canvas.height);

				context.strokeStyle = 'blue';
				context.beginPath();
				context.moveTo(0, canvas.height - frequency[0]*canvas.height/255);
				for(var i=0; i<frequency.length; i++){
					context.lineTo(
						i*canvas.width/frequency.length,
						canvas.height - Math.max(0, frequency[i]*canvas.height/255)
					);
				}
				context.stroke();

				context.strokeStyle = 'red';
				context.beginPath();
				context.moveTo(0, canvas.height/2 + timeDomain[0]*canvas.height/2);
				for(var i=0; i<timeDomain.length; i++){
					context.lineTo(
						i*canvas.width/timeDomain.length,
						canvas.height/2 + timeDomain[i]*canvas.height/2
					);
				}
				context.stroke();

				requestAnimationFrame(animation);
			})();

		},
		console.log
	);
	</script>
```
配列と[AudioContext](https://developer.mozilla.org/en-US/docs/Web/API/AudioContext)とやらを作って、[AnalyzerNode](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode)を<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioNode" target="_blank">AudioSourceNode</a>に接続。
あとは{{getFloatTimeDomainData}}ってやつで波形、{{getByteFrequencyData}}ってやつで周波数（波形をフーリエ変換したやつ）を取得出来ます。
どちらも{{getFloat}}を使うと浮動小数点で、{{getByte}}から始まるやつを使うと0から255までの値で取得出来ます。分かりやすくて良いね。

マイクからリアルタイムに音を取得したい場合は{{createMediaStreamSource}}の代わりに{{createMediaElementSource}}を使います。大体こんな感じ。
``` html
	<audio src="music.mp3" controls></audio>
	<script>
		var audioContext = new AudioContext();
		var analyser = audioContext.createAnalyser();
		audioContext.createMediaElementSource(document.querySelector('audio')).connect(analyser);
	</script>
```
それ以外の使い方は一緒です。getUserMediaとかやらなくて良いだけもっとシンプル。

普通にcanvasを使っているので、わりと何でも出来ます。楽しい。
<canvas style="border: 1px solid black;" width=640 height=480 id=mic_frequency_two></canvas>
余談ですが、google chromeでgetUserMediaを使おうとする場合はhttpsを使わないといけないようです。Firefoxとかは分からん。
そんなわけでこのページもHTTPSになってるはず。

(((
	<audio muted></audio>
	<script defer>
	if(location.protocol != 'https:'){
		location.protocol = 'https://';
	}
	navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;

	var canvas = document.querySelector('#mic_frequency_one');
	var context = canvas.getContext('2d');

	var two = document.querySelector('#mic_frequency_two');
	var twoCtx = two.getContext('2d');

	canvas.width = canvas.offsetWidth;
	canvas.height = canvas.offsetHeight;
	twoCtx.width = twoCtx.offsetWidth;
	twoCtx.height = twoCtx.offsetHeight;

	navigator.getUserMedia(
		{audio: true},
		function(stream){
			document.querySelector('audio').src = URL.createObjectURL(stream);
			var audioContext = new AudioContext();
			var analyser = audioContext.createAnalyser();
			var timeDomain = new Float32Array(analyser.frequencyBinCount);
			var frequency = new Uint8Array(analyser.frequencyBinCount);
			audioContext.createMediaStreamSource(stream).connect(analyser);

			var old = 0;
			var beacons = [];
			var beacon_max = Math.sqrt(Math.pow(two.width, 2) + Math.pow(two.height, 2));

			(function animation(){
				analyser.getFloatTimeDomainData(timeDomain);
				analyser.getByteFrequencyData(frequency);

				context.clearRect(0, 0, canvas.width, canvas.height);

				context.strokeStyle = 'blue';
				context.beginPath();
				context.moveTo(0, canvas.height - frequency[0]*canvas.height/255);
				for(var i=0; i<frequency.length; i++){
					context.lineTo(
						i*canvas.width/frequency.length,
						canvas.height - Math.max(0, frequency[i]*canvas.height/255)
					);
				}
				context.stroke();

				context.strokeStyle = 'red';
				context.beginPath();
				context.moveTo(0, canvas.height/2 + timeDomain[0]*canvas.height/2);
				for(var i=0; i<timeDomain.length; i++){
					context.lineTo(
						i*canvas.width/timeDomain.length,
						canvas.height/2 + timeDomain[i]*canvas.height/2
					);
				}
				context.stroke();

				var score = frequency.reduce(function(prev, current){
					return prev + current;
				});
				if(old*1.05 < score){
					beacons.push([0, old*50/score]);
				}
				old = score;

				twoCtx.clearRect(0, 0, two.width, two.height);
				twoCtx.fillStyle = 'black';

				beacons = beacons.filter(function(x){
					return x[0] < beacon_max;
				}).map(function(x){
					twoCtx.globalCompositeOperation = 'source-over';
					twoCtx.beginPath();
					twoCtx.arc(two.width, two.height, x[0], 0, Math.PI*2);
					twoCtx.fill();

					twoCtx.globalCompositeOperation = 'xor';
					twoCtx.beginPath();
					twoCtx.arc(two.width, two.height, x[0]+x[1], 0, Math.PI*2);
					twoCtx.fill();

					return [x[0]+10, x[1]];
				});

				twoCtx.beginPath();
				twoCtx.arc(two.width, two.height, score/timeDomain.length, 0, Math.PI*2);
				twoCtx.fill();

				requestAnimationFrame(animation);
			})();

		},
		console.log
	);
	</script>
)))
